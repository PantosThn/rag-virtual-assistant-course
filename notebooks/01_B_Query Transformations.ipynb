{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c512e052-86bb-4e3b-afd5-b03838dbf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load from .env if you use one\n",
    "load_dotenv()\n",
    "os.environ[\"USER_AGENT\"] = (\n",
    "    \"Mozilla/5.0 (compatible; RAG-TutorialBot/1.0; +https://yourwebsite.com/bot)\"\n",
    ")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "from langchain.schema import Document\n",
    "from langchain.load import dumps, loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc497f07-4185-44a8-a488-36ba152e6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGSMITH_PROJECT = \"rag-virtual-assistant-course\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a031f25a-9a22-4204-ba7b-d84b7aa35f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from the web\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=[\n",
    "        \"https://www.reuters.com/world/europe/greece-ask-eu-fiscal-leeway-defence-spending-minister-says-2025-04-29/\",\n",
    "        \"https://www.ekathimerini.com/economy/1264299/moodys-upgrade-of-the-greek-economy-is-significant-says-govt-spox/\",\n",
    "        \"https://www.imf.org/en/News/Articles/2025/04/04/pr2589-greece-imf-executive-board-concludes-2025-article-iv-consultation\",\n",
    "        \"https://economy-finance.ec.europa.eu/economic-surveillance-eu-economies/greece/economic-forecast-greece_en\",\n",
    "        \"https://www.reuters.com/markets/europe/greece-repay-first-bailout-loans-by-2031-10-years-early-2025-04-11/\",\n",
    "        \"https://www.reuters.com/world/europe/bribery-scandals-greeces-public-sector-show-persistence-corruption-2025-03-27\",\n",
    "        \"https://www.reuters.com/markets/europe/greek-economy-surges-after-decade-pain-2024-04-18/\",\n",
    "    ],\n",
    "    bs_kwargs={\n",
    "        # Optional: you can remove `bs_kwargs` if the websites don't need specific filtering\n",
    "        \"parse_only\": bs4.SoupStrainer(\n",
    "            [\"article\", \"body\", \"main\", \"section\", \"div\", \"p\"]\n",
    "        )\n",
    "    },\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split documents into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Check for available API keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Create vectorstore with OpenAI embeddings\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    embedder = OpenAIEmbeddings()\n",
    "else:\n",
    "    embedder = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedder)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03aec4a-bd38-4a74-a093-d39a26511c65",
   "metadata": {},
   "source": [
    "# Multi query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb9fc58-c1f2-47f6-b195-8178489c2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543eec1c-63c1-4e57-81d0-1b3ce521d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1. What were the primary causes of the Greek debt crisis?\n",
      "2. 2. Can you outline the key factors that contributed to the Greek debt crisis?\n",
      "3. 3. What were the underlying reasons behind the Greek debt crisis?\n",
      "4. 4. What factors played a significant role in triggering the Greek debt crisis?\n",
      "5. 5. What were the major influences that precipitated the Greek debt crisis?\n"
     ]
    }
   ],
   "source": [
    "question = \"What were the main factors that led to the Greek debt crisis?\"\n",
    "\n",
    "queries = generate_queries.invoke({\"question\": question})\n",
    "\n",
    "for i, q in enumerate(queries, 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27df07b-2bce-4883-9078-b54de9cf79dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/v_kz_tz15cjf811kh6rsnyj00000gp/T/ipykernel_25767/1384165108.py:8: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\"Unique union of retrieved docs\"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be881c33-68b3-42af-9765-f22876de8ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main factors that led to the Greek debt crisis included high public debt levels, tax evasion, budget deficits, non-performing loans, and structural imbalances in the economy.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1a582-8b95-46ad-9f77-38c5f81d4276",
   "metadata": {},
   "source": [
    "# Query Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3a85448-502b-468d-9f76-cfc7b8ee7bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Preparing query decomposition prompt...\n",
      "\n",
      " Original Question:\n",
      "How did tourism affect the Greek economy in 2023 compared to 2022?\n",
      "\n",
      " Rewritten Subqueries:\n",
      "1. How did tourism revenue in Greece change from 2022 to 2023?\n",
      "2. What impact did the number of tourists visiting Greece have on the economy in 2023 compared to 2022?\n",
      "\n",
      " Simulating retrieval of relevant documents...\n",
      "\n",
      " Retrieved Documents:\n",
      "Doc 1: In 2023, tourism contributed 25% more revenue compared to 2022, driven by record-breaking arrivals in July and August.\n",
      "Doc 2: The Greek economy in 2022 saw a 20% recovery in tourism, following the pandemic lows of 2020 and 2021.\n",
      "Doc 3: The GDP from tourism rose from 15% of total GDP in 2022 to nearly 18% in 2023, according to ELSTAT.\n",
      "\n",
      " Generating the final answer using retrieved context...\n",
      "\n",
      "üéØ Final Answer:\n",
      "Tourism significantly boosted the Greek economy in 2023 compared to 2022, with a 25% increase in revenue and a rise in the GDP contribution from nearly 15% to almost 18%.\n"
     ]
    }
   ],
   "source": [
    "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a helpful assistant that rewrites the user's question \"\n",
    "     \"into multiple focused subqueries to improve document retrieval.\"),\n",
    "    (\"human\", \n",
    "     \"Original question: {question}\\n\\nRewrite it into 2-3 targeted subquestions, \"\n",
    "     \"each on a new line, without bullet points.\")\n",
    "])\n",
    "\n",
    "\n",
    "# Define a prompt for rewriting\n",
    "print(\"\\n Preparing query decomposition prompt...\")\n",
    "decomposition_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# Run decomposition on a complex user question\n",
    "\n",
    "question = \"How did tourism affect the Greek economy in 2023 compared to 2022?\"\n",
    "print(f\"\\n Original Question:\\n{question}\")\n",
    "\n",
    "rewrites = decomposition_chain.invoke({\"question\": question})\n",
    "rewrite_list = [r.strip() for r in rewrites.splitlines() if r.strip()]\n",
    "\n",
    "print(\"\\n Rewritten Subqueries:\")\n",
    "for i, q in enumerate(rewrite_list, 1):\n",
    "    print(f\"{i}. {q}\")\n",
    "\n",
    "\n",
    "# Simulate retrieved documents (from a vector DB)\n",
    "print(\"\\n Simulating retrieval of relevant documents...\")\n",
    "retrieved_docs = [\n",
    "    Document(page_content=\"In 2023, tourism contributed 25% more revenue compared to 2022, driven by record-breaking arrivals in July and August.\"),\n",
    "    Document(page_content=\"The Greek economy in 2022 saw a 20% recovery in tourism, following the pandemic lows of 2020 and 2021.\"),\n",
    "    Document(page_content=\"The GDP from tourism rose from 15% of total GDP in 2022 to nearly 18% in 2023, according to ELSTAT.\"),\n",
    "]\n",
    "\n",
    "print(\"\\n Retrieved Documents:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"Doc {i}: {doc.page_content}\")\n",
    "\n",
    "\n",
    "# Feed context into the final answer generation prompt\n",
    "print(\"\\n Generating the final answer using retrieved context...\")\n",
    "GEN_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"Answer using only the context below. \"\n",
    "    \"If insufficient, share any partial info you have **and** explicitly say \"\n",
    "    \"\\\"I don't know\\\" where details are missing.\\n\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Question: {question}\\nAnswer:\"\n",
    ") | llm | StrOutputParser()\n",
    "\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "final_answer = GEN_PROMPT.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "\n",
    "# Present the final answer\n",
    "print(\"\\nüéØ Final Answer:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432710c-07f7-47e5-9784-cfa2502dc66c",
   "metadata": {},
   "source": [
    "# HYDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2216f2c-80da-4761-98ac-f58f7060f1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Generating hypothetical answer...\n",
      "\n",
      "üìù Hypothetical Answer:\n",
      " Greek inflation has been relatively low in recent years, with the country experiencing an average inflation rate of around 0.5% in 2020. This is largely due to the economic challenges faced by Greece in the aftermath of the financial crisis, which led to a period of deflation and slow economic growth. However, with the country's economy gradually recovering and the implementation of structural reforms, inflation is expected to pick up slightly in the coming years.\n",
      "\n",
      "One factor that could contribute to higher inflation in Greece is the increase in consumer demand as the economy improves. This could lead to higher prices for goods and services, especially in sectors such as tourism and hospitality. Additionally, rising energy prices and global supply chain disruptions could also put upward pressure on inflation in Greece.\n",
      "\n",
      "Overall, while Greek inflation is currently low, there are factors that could lead to an increase in the coming years. It will be important for policymakers to monitor these developments closely and take appropriate measures to ensure that inflation remains at a stable and manageable level.\n",
      "\n",
      "üìö Retrieved Documents:\n",
      "\n",
      "Doc 1:\n",
      "at a slow pace¬†Headline inflation averaged 3.1% y-o-y in the third quarter of 2024, about 1 pp. above the euro area average. Disinflation has been constrained by accelerating services prices, the impact of the 2023 floods on food prices and the recent uptick in electricity prices. Inflation is expected to resume its decline in the last quarter of 2024, but wage pressures fuelled by increasing labour shortages and minimum wage increases are set to exert upward pressure on prices looking forward. \n",
      "\n",
      "Doc 2:\n",
      "at a slow pace¬†Headline inflation averaged 3.1% y-o-y in the third quarter of 2024, about 1 pp. above the euro area average. Disinflation has been constrained by accelerating services prices, the impact of the 2023 floods on food prices and the recent uptick in electricity prices. Inflation is expected to resume its decline in the last quarter of 2024, but wage pressures fuelled by increasing labour shortages and minimum wage increases are set to exert upward pressure on prices looking forward. \n",
      "\n",
      "Doc 3:\n",
      "Growth to remain robust¬†The Greek economy posted a solid 2.1% y-o-y growth in the first half of 2024, driven primarily by domestic demand, while net exports were a drag on growth. Following minimum wage hikes, private consumption benefited from the relatively faster wage increase for lower-income households that tend to have a higher propensity to consume. Equipment investment accelerated in parallel with a strong pick-up in corporate credit growth, while a surge in imports accompanied by sluggi\n",
      "\n",
      "üéØ Final Answer:\n",
      "\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Your existing vectorstore and retriever are already running\n",
    "# from main app, so we'll just use the retriever here\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# HYDE step: create a plausible hypothetical answer\n",
    "hyde_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a plausible, informed answer to the question below as if you were confident and had access to expert data.\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    ")\n",
    "hyde_chain = hyde_prompt | llm | parser\n",
    "\n",
    "question = \"Greek inflation\"\n",
    "print(\"üîÆ Generating hypothetical answer...\")\n",
    "hypothetical_answer = hyde_chain.invoke({\"question\": question})\n",
    "print(\"\\nüìù Hypothetical Answer:\\n\", hypothetical_answer)\n",
    "\n",
    "# Use that as the query for the vectorstore\n",
    "retrieved_docs = retriever.invoke(hypothetical_answer)\n",
    "\n",
    "print(\"\\nüìö Retrieved Documents:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\nDoc {i}:\\n{doc.page_content.strip()[:500]}\")  # Truncated for clarity\n",
    "\n",
    "# Final generation using retrieved context\n",
    "GEN_PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"Answer the user's question using ONLY the context below. \"\n",
    "    \"If the context is insufficient, say \\\"I don't know\\\".\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    ")\n",
    "gen_chain = GEN_PROMPT | llm | parser\n",
    "\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "final_answer = gen_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "print(\"\\nüéØ Final Answer:\\n\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ef00d-f6aa-41d9-b5f3-075a827265c3",
   "metadata": {},
   "source": [
    "# Evaluate the outcome with another llm (LLM as a jury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fd6070-8d6d-4678-b78b-a7eecb131ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LLM Jury Evaluation:\n",
      "\n",
      "Faithfulness: 4/5 ‚Äî The answer provides relevant information about Greek inflation, including current trends and future projections.\n",
      "Relevance: 3/5 ‚Äî The answer is somewhat relevant to the user question about Greek inflation, but it also includes information about other economic indicators in Greece.\n",
      "Fluency: 4/5 ‚Äî The answer is well-written and easy to understand.\n",
      "Completeness: 3/5 ‚Äî The answer could be more focused on Greek inflation specifically and provide more detailed information on the topic.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Load jury model\n",
    "jury_llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# ‚ú® Strict evaluation prompt with injected inputs\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are an expert evaluator for a question answering system.\n",
    "\n",
    "Evaluate the answer based on the following:\n",
    "User Question: {question}\n",
    "\n",
    "Retrieved Context:\n",
    "{context}\n",
    "\n",
    "Final Answer:\n",
    "{answer}\n",
    "\n",
    "Evaluate the answer on a scale of 1 to 5 for each criterion and give a short reason.\n",
    "\n",
    "Format your response like this:\n",
    "Faithfulness: x/5 ‚Äî ...\n",
    "Relevance: x/5 ‚Äî ...\n",
    "Fluency: x/5 ‚Äî ...\n",
    "Completeness: x/5 ‚Äî ...\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Build the chain and run\n",
    "evaluation_chain = prompt | llm | parser\n",
    "result = evaluation_chain.invoke({\n",
    "    \"question\": question,\n",
    "    \"context\": context,\n",
    "    \"answer\": final_answer,\n",
    "})\n",
    "\n",
    "print(\"üìä LLM Jury Evaluation:\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f1a43-d09c-4aa8-83a0-5e2750864838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
